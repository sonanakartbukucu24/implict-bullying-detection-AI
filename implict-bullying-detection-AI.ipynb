{"cells":[{"cell_type":"markdown","source":["***Sistemin saglikli calismasi icin GPU olarak Tesla T4(Colab)kullanildi, train islemleri bu veya ortalama RTX veya GTX(yalnizca en ust kartlarindan) serisi kartlar kullanilabilir.***"],"metadata":{"id":"ydGt8eApLCyN"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2550,"status":"ok","timestamp":1764457759262,"user":{"displayName":"Ali Hamza Anaç","userId":"01588361416155150077"},"user_tz":-180},"id":"o2_nFz5_jXLb","outputId":"92bfef2a-5ca7-4d84-c979-d1a0671a3c0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","\n","DATA_PATH = \"/content/drive/MyDrive/ortuk_zorbalik_v2/dataset.json\"\n","CKPT_PATH = \"/content/drive/MyDrive/ortuk_zorbalik_v2/checkpoints\"\n","FINAL_MODEL_PATH = \"/content/drive/MyDrive/ortuk_zorbalik_v2/model_final\"\n","\n","os.makedirs(CKPT_PATH, exist_ok=True)\n","os.makedirs(FINAL_MODEL_PATH, exist_ok=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32070,"status":"ok","timestamp":1764457791334,"user":{"displayName":"Ali Hamza Anaç","userId":"01588361416155150077"},"user_tz":-180},"id":"JZ8Bp-WnjYcA","outputId":"346778fe-706e-4492-f990-7b4cfc49838e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: transformers 4.57.3\n","Uninstalling transformers-4.57.3:\n","  Successfully uninstalled transformers-4.57.3\n"]}],"source":["!pip uninstall -y transformers\n","!pip install transformers==4.57.3 datasets accelerate evaluate scikit-learn -q\n","\n","import sys\n","if \"transformers\" in sys.modules:\n","    del sys.modules[\"transformers\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LoIsPRoTjZkv"},"outputs":[],"source":["from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, BertConfig\n","import evaluate\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","dataset = load_dataset(\"json\", data_files=DATA_PATH)\n","\n","def transform(example):\n","    return {\"text\": example[\"input\"], \"label\": example[\"output\"]}\n","\n","dataset = dataset.map(transform)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wz_JPY8Yja71"},"outputs":[],"source":["labels = sorted(list(set(dataset[\"train\"][\"label\"])))\n","label2id = {l:i for i,l in enumerate(labels)}\n","id2label = {i:l for l,i in label2id.items()}\n","\n","def encode_label(example):\n","    example[\"label\"] = label2id[example[\"label\"]]\n","    if \"labels\" in example:\n","        del example[\"labels\"]\n","    return example\n","\n","dataset = dataset.map(encode_label)\n","num_labels = len(labels)\n","\n","dataset = dataset[\"train\"].train_test_split(test_size=0.1, shuffle=True, seed=42)\n","train_dataset = dataset[\"train\"]\n","valid_dataset = dataset[\"test\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1624,"status":"ok","timestamp":1764457818136,"user":{"displayName":"Ali Hamza Anaç","userId":"01588361416155150077"},"user_tz":-180},"id":"HVi8MSwkjcnJ","outputId":"b5ba1af6-a9df-4dd2-adc3-93111e38e072"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["model_name = \"dbmdz/bert-base-turkish-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","def tokenize(batch):\n","    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=128)\n","\n","train_tokenized = train_dataset.map(tokenize, batched=True)\n","valid_tokenized = valid_dataset.map(tokenize, batched=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10113,"status":"ok","timestamp":1764457828250,"user":{"displayName":"Ali Hamza Anaç","userId":"01588361416155150077"},"user_tz":-180},"id":"Dc_-J8SkjeEM","outputId":"aa540906-f1a8-4360-dd31-844f60099c3f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForSequenceClassification, BertConfig, BitsAndBytesConfig\n","from peft import LoraConfig, get_peft_model\n","\n","model_name = \"dbmdz/bert-base-turkish-uncased\"\n","\n","config = BertConfig.from_pretrained(model_name)\n","config.num_labels = num_labels  # Senin label sayın\n","\n","bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n","\n","from transformers import BitsAndBytesConfig\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_8bit=True,\n","    llm_int8_threshold=6.0,\n","    llm_int8_has_fp16_weight=False,\n",")\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    config=config,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\"\n",")\n","\n","\n","lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    target_modules=[\"query\", \"value\"],  # BERT için genelde bu modüller\n","    lora_dropout=0.1,\n","    bias=\"none\",\n","    task_type=\"SEQ_CLS\"\n",")\n","\n","model = get_peft_model(model, lora_config)\n","\n","# Freeze işlemi\n","for name, param in model.named_parameters():\n","    if \"encoder.layer.\" in name:\n","        layer_num = int(name.split(\"encoder.layer.\")[1].split(\".\")[0])\n","        if layer_num < 8:\n","            param.requires_grad = False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0bWJYn1jfS7"},"outputs":[],"source":["class TrainerWithLabelSmoothing(Trainer):\n","    def __init__(self, *args, smoothing=0.1, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.smoothing = smoothing\n","        self.criterion = nn.CrossEntropyLoss(label_smoothing=smoothing)\n","\n","    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n","        labels = inputs.get(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs.get(\"logits\")\n","        loss = self.criterion(logits, labels)\n","        return (loss, outputs) if return_outputs else loss\n"]},{"cell_type":"code","source":["from transformers import BitsAndBytesConfig\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_8bit=True,\n","    llm_int8_threshold=6.0,\n","    llm_int8_has_fp16_weight=False,\n",")\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    config=config,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\"\n",")\n","\n","model = get_peft_model(model, lora_config)\n","\n","for name, param in model.named_parameters():\n","    if \"encoder.layer.\" in name:\n","        layer_num = int(name.split(\"encoder.layer.\")[1].split(\".\")[0])\n","        if layer_num < 8:\n","            param.requires_grad = False\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OtessKwz4Dpk","executionInfo":{"status":"ok","timestamp":1764457829597,"user_tz":-180,"elapsed":1328,"user":{"displayName":"Ali Hamza Anaç","userId":"01588361416155150077"}},"outputId":"4375da89-2690-4394-c858-dd9c47ee16fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_0zRoC4hjg_A"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=CKPT_PATH,\n","    eval_strategy=\"steps\",\n","    eval_steps=100,\n","    save_strategy=\"steps\",\n","    save_steps=100,\n","    logging_steps=50,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    gradient_accumulation_steps=2,\n","    num_train_epochs=1,\n","    learning_rate=3e-4,\n","    weight_decay=0.1,\n","    warmup_ratio=0.1,\n","    fp16=False,\n","    bf16=False,\n","    load_best_model_at_end=True,\n","    save_total_limit=3,\n","    gradient_checkpointing=True,\n","    optim=\"adamw_torch\",\n","    report_to=[]\n",")\n","\n","metric = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=-1)\n","    acc = np.mean(preds == labels)\n","    return {\"accuracy\": acc}\n"]},{"cell_type":"code","source":["# LoRA classifier modüllerini FP32'ye çevir\n","for name, param in model.named_parameters():\n","    if \"modules_to_save\" in name:\n","        param.data = param.data.to(torch.float32)\n","        param.requires_grad = True\n","        if param.grad is not None:\n","            param.grad = None\n","\n","print(\"modules_to_save parametreleri FP32'ye çevrildi.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oDllBPtO8MR8","executionInfo":{"status":"ok","timestamp":1764458817257,"user_tz":-180,"elapsed":25,"user":{"displayName":"Ali Hamza Anaç","userId":"01588361416155150077"}},"outputId":"c8cb96dd-a937-41c1-d22b-91888e644d54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["modules_to_save parametreleri FP32'ye çevrildi.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":972},"executionInfo":{"elapsed":314526,"status":"ok","timestamp":1764459133903,"user":{"displayName":"Ali Hamza Anaç","userId":"01588361416155150077"},"user_tz":-180},"id":"bksCaG7jjjQM","outputId":"90807002-8067-479a-848e-a15d5ebefd59"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-599064265.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `TrainerWithLabelSmoothing.__init__`. Use `processing_class` instead.\n","  super().__init__(*args, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='844' max='844' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [844/844 05:09, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>1.230600</td>\n","      <td>1.145846</td>\n","      <td>0.570667</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.993600</td>\n","      <td>0.974945</td>\n","      <td>0.628000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.920800</td>\n","      <td>0.857388</td>\n","      <td>0.732667</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.837500</td>\n","      <td>0.778757</td>\n","      <td>0.852667</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.781000</td>\n","      <td>0.738709</td>\n","      <td>0.866000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.754100</td>\n","      <td>0.710378</td>\n","      <td>0.886000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.746100</td>\n","      <td>0.696341</td>\n","      <td>0.910000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.732800</td>\n","      <td>0.687228</td>\n","      <td>0.895333</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=844, training_loss=0.8889546416947062, metrics={'train_runtime': 310.8202, 'train_samples_per_second': 43.433, 'train_steps_per_second': 2.715, 'total_flos': 181630087236000.0, 'train_loss': 0.8889546416947062, 'epoch': 1.0})"]},"metadata":{},"execution_count":18}],"source":["trainer = TrainerWithLabelSmoothing(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_tokenized,\n","    eval_dataset=valid_tokenized,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",")\n","\n","trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":669,"status":"ok","timestamp":1764459355316,"user":{"displayName":"Ali Hamza Anaç","userId":"01588361416155150077"},"user_tz":-180},"id":"Nh4H8lZUjjpf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"22e2fbe6-2ebb-4f16-d0af-67001d744677"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model ve tokenizer '/content/drive/MyDrive/ortuk_zorbalik_v2/model_final' klasörüne kaydedildi.\n"]}],"source":["model.save_pretrained(FINAL_MODEL_PATH)\n","tokenizer.save_pretrained(FINAL_MODEL_PATH)\n","\n","print(f\"Model ve tokenizer '{FINAL_MODEL_PATH}' klasörüne kaydedildi.\")\n"]},{"cell_type":"markdown","source":["***Buradan sonrasindaki kodlari calistirin, olmadan sistem calismayacaktir.***"],"metadata":{"id":"PeTy076nCQya"}},{"cell_type":"code","source":["!pip show transformers bitsandbytes peft\n"],"metadata":{"collapsed":true,"id":"zYA7z7Y8xkWV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -f ~/.cache/huggingface/accelerate/default_config.yaml\n"],"metadata":{"id":"bg0Hk8qG6AS4"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPh9jTc1m+E1rp8+lp87qO9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}